#############################################
Run training for a new model (SMPL)
#############################################

python mhc/mhc_train.py \
--train_run \
--visualize_policy \
--num_envs 3 \
--xbox_interactive \
--demo_motion_ids 9999 \
--mlp_units 1024,512 \
--disc_units 1024,512 \
--lk_encoder_units 1024,1024 \
--lk_embedding_dim 64 \
--max_epochs 200000 \
--motion_lib_device cpu \
--cfg_env mhc/data/cfg/humanoid_mhc_smpl_catchup.yaml \
--cfg_train mhc/data/cfg/train/rlg/mhc_humanoid_catchup.yaml \
--motion_file mhc/data/motions/amass/amp_humanoid_amass_dataset.yaml \
--wandb_project mhc_smpl_train \
--wandb_path WANDB_USERNAME/mhc_smpl_train/wandbRunID/latest_model.pth \
--disable_early_termination \
--energy_penalty \
--penalty_multiplyer 2 \
--switch_demos_within_episode \
--init_state_rotate \
--demo_rotate

#############################################
Run play using a trained model (SMPL)
#############################################

python mhc/mhc_play.py \
--visualize_policy \
--num_envs 3 \
--xbox_interactive \
--env_spacing 1.5 \
--demo_motion_ids 9999 \
--mlp_units 1024,512 \
--disc_units 1024,512 \
--lk_encoder_units 1024,1024 \
--lk_embedding_dim 64 \
--max_epochs 200000 \
--motion_lib_device cpu \
--cfg_env mhc/data/cfg/humanoid_mhc_smpl_catchup.yaml \
--cfg_train mhc/data/cfg/train/rlg/mhc_humanoid_catchup.yaml \
--motion_file mhc/data/motions/amass/amp_humanoid_amass_dataset.yaml \
--wandb_project mhc_smpl_train \
--wandb_path WANDB_USERNAME/mhc_smpl_train/wandbRunID/latest_model.pth \
--disable_early_termination \
--energy_penalty \
--penalty_multiplyer 2 \
--switch_demos_within_episode \
--init_state_rotate \
--demo_rotate

#############################################
Run training for a new model (reallusion)
#############################################

python mhc/mhc_play.py \
--train_run \
--visualize_policy \
--num_envs 3 \
--xbox_interactive \
--env_spacing 1.5 \
--demo_motion_ids 9999 \
--mlp_units 1024,512 \
--disc_units 1024,512 \
--lk_encoder_units 1024,1024 \
--lk_embedding_dim 64 \
--max_epochs 200000 \
--motion_lib_device cpu \
--cfg_env mhc/data/cfg/humanoid_mhc_sword_shield_catchup.yaml \
--cfg_train mhc/data/cfg/train/rlg/mhc_humanoid_catchup.yaml \
--motion_file mhc/data/motions/reallusion_sword_shield/dataset_reallusion_sword_shield.yaml \
--wandb_project mhc_reallusion_train \
--wandb_path WANDB_USERNAME/mhc_reallusion_train/wandbRunID/latest_model.pth \
--disable_early_termination \
--energy_penalty \
--penalty_multiplyer 2 \
--switch_demos_within_episode \
--init_state_rotate \
--demo_rotate

#############################################
Run play using a trained model (reallusion)
#############################################

python mhc/mhc_train.py \
--visualize_policy \
--num_envs 3 \
--xbox_interactive \
--env_spacing 1.5 \
--demo_motion_ids 9999 \
--mlp_units 1024,512 \
--disc_units 1024,512 \
--lk_encoder_units 1024,1024 \
--lk_embedding_dim 64 \
--max_epochs 200000 \
--disable_early_termination \
--motion_lib_device cpu \
--cfg_env mhc/data/cfg/humanoid_mhc_sword_shield_catchup.yaml \
--cfg_train mhc/data/cfg/train/rlg/mhc_humanoid_catchup.yaml \
--motion_file mhc/data/motions/reallusion_sword_shield/dataset_reallusion_sword_shield.yaml \
--wandb_project mhc_reallusion_train \
--wandb_path WANDB_USERNAME/mhc_reallusion_train/wandbRunID/latest_model.pth \
--energy_penalty \
--penalty_multiplyer 2 \
--switch_demos_within_episode \
--init_state_rotate \
--demo_rotate